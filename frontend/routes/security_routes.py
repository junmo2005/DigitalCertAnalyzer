from flask import request, jsonify, send_file
import os
import traceback
import shutil
import threading
import queue
import uuid
from datetime import datetime
from werkzeug.utils import secure_filename
from certificate_security_enhancer import CertificateSecurityEnhancer
from cryptography import x509
from cryptography.hazmat.backends import default_backend
from utils.file_utils import is_valid_domain, extract_archive, find_certificate_files, safe_division
from services.deepseek_service import (
    generate_ai_report, 
    generate_security_default_report,
    generate_certificate_default_report
)
import logging
import json
from services.task_queue import task_queue

logger = logging.getLogger(__name__)

def register_security_routes(app, upload_folder, reports_folder, pinning_db_path):
    """æ³¨å†Œå®‰å…¨åˆ†æè·¯ç”±"""
    
    security_enhancer = CertificateSecurityEnhancer(pinning_db_path)
    
    # ==================== å®‰å…¨åˆ†æAPIè·¯ç”± ====================
    
    @app.route('/api/security/analyze-domain', methods=['POST'])
    def analyze_domain_security():
        """åˆ†æå•ä¸ªåŸŸåå®‰å…¨çŠ¶æ€"""
        try:
            data = request.get_json()
            domain = data.get('domain')
            
            if not domain:
                return jsonify({'status': 'error', 'error': 'åŸŸåä¸èƒ½ä¸ºç©º'}), 400
            
            logger.info(f"å¼€å§‹å®‰å…¨åˆ†æ: {domain}")

            security_report = security_enhancer.analyze_domain_security(domain)
            
            logger.info(f"HSTSæ£€æµ‹ç»“æœ: {security_report.get('hsts', {})}")
            logger.info(f"HTTPSé‡å®šå‘ç»“æœ: {security_report.get('https_enforcement', {})}")

            security_score = security_enhancer._calculate_comprehensive_security_score(security_report)
            security_report['security_score'] = security_score
            
            return jsonify({
                'status': 'success',
                'security_report': security_report
            })
            
        except Exception as e:
            logger.error(f"åŸŸåå®‰å…¨åˆ†æå¤±è´¥: {str(e)}")
            return jsonify({'status': 'error', 'error': f'å®‰å…¨åˆ†æå¤±è´¥: {str(e)}'}), 500
    
    @app.route('/api/security/pin-certificate', methods=['POST'])
    def pin_certificate():
        """è¯ä¹¦é’‰æ‰é…ç½®"""
        try:
            domain = request.form.get('domain')
            pin_type = request.form.get('pin_type', 'leaf')
            cert_file = request.files.get('cert_file')
            
            if not all([domain, cert_file]):
                return jsonify({'status': 'error', 'error': 'åŸŸåå’Œè¯ä¹¦æ–‡ä»¶ä¸èƒ½ä¸ºç©º'}), 400
            
            cert_data = cert_file.read()
            
            if not cert_data:
                return jsonify({'status': 'error', 'error': 'è¯ä¹¦æ–‡ä»¶ä¸ºç©º'}), 400
            
            try:
                cert = x509.load_der_x509_certificate(cert_data, default_backend())
            except ValueError:
                try:
                    cert = x509.load_pem_x509_certificate(cert_data, default_backend())
                except ValueError:
                    return jsonify({'status': 'error', 'error': 'æ— æ³•è§£æè¯ä¹¦æ–‡ä»¶ï¼Œè¯·ç¡®ä¿è¯ä¹¦æ ¼å¼æ­£ç¡®'}), 400
            
            pinned = security_enhancer.pin_certificate(domain, cert_data, pin_type)
            
            if pinned:
                return jsonify({
                    'status': 'success',
                    'message': f'è¯ä¹¦é’‰æ‰é…ç½®æˆåŠŸ - åŸŸå: {domain}, ç±»å‹: {pin_type}',
                    'certificate_hash': security_enhancer.calculate_certificate_hash(cert_data)
                })
            else:
                return jsonify({'status': 'error', 'error': 'è¯ä¹¦é’‰æ‰å¤±è´¥'}), 500
            
        except Exception as e:
            logger.error(f"è¯ä¹¦é’‰æ‰å¤±è´¥: {str(e)}")
            return jsonify({'status': 'error', 'error': f'è¯ä¹¦é’‰æ‰å¤±è´¥: {str(e)}'}), 500
    
    @app.route('/api/security/check-chain', methods=['POST'])
    def check_certificate_chain():
        """æ£€æŸ¥è¯ä¹¦é“¾å®Œæ•´æ€§"""
        try:
            cert_files = request.files.getlist('cert_files[]')
            
            if not cert_files:
                return jsonify({'status': 'error', 'error': 'è¯·é€‰æ‹©è¯ä¹¦æ–‡ä»¶'}), 400
            
            cert_chain = []
            file_info = []
            
            for cert_file in cert_files:
                if cert_file.filename == '':
                    continue
                    
                cert_data = cert_file.read()
                if cert_data:
                    cert_chain.append(cert_data)
                    file_info.append({
                        'filename': cert_file.filename,
                        'size': len(cert_data)
                    })
            
            if not cert_chain:
                return jsonify({'status': 'error', 'error': 'æœªæ‰¾åˆ°æœ‰æ•ˆçš„è¯ä¹¦æ–‡ä»¶'}), 400
            
            chain_valid, issues, detailed_report = security_enhancer.chain_validator.validate_certificate_chain(cert_chain)
            
            return jsonify({
                'status': 'success',
                'chain_valid': chain_valid,
                'issues': issues,
                'file_info': file_info,
                'detailed_report': detailed_report
            })
            
        except Exception as e:
            logger.error(f"è¯ä¹¦é“¾éªŒè¯å¤±è´¥: {str(e)}")
            return jsonify({'status': 'error', 'error': f'è¯ä¹¦é“¾éªŒè¯å¤±è´¥: {str(e)}'}), 500
    
    @app.route('/api/security/batch-analyze', methods=['POST'])
    def batch_security_analyze():
        """æ‰¹é‡åŸŸåå®‰å…¨åˆ†æ"""
        try:
            data = request.get_json()
            domains = data.get('domains', [])
            
            if not domains:
                return jsonify({'status': 'error', 'error': 'åŸŸååˆ—è¡¨ä¸èƒ½ä¸ºç©º'}), 400
            
            valid_domains = []
            for domain in domains:
                domain = domain.strip()
                if domain and '.' in domain:
                    valid_domains.append(domain)
            
            if not valid_domains:
                return jsonify({'status': 'error', 'error': 'æœªæä¾›æœ‰æ•ˆçš„åŸŸå'}), 400
            
            logger.info(f"å¼€å§‹æ‰¹é‡å®‰å…¨åˆ†æï¼ŒåŸŸåæ•°é‡: {len(valid_domains)}")
            
            security_report = security_enhancer.generate_security_report(valid_domains)
            
            score_distribution = [0, 0, 0, 0]
            feature_stats = {
                'pinning': 0,
                'https': 0,
                'hsts': 0,
                'good_headers': 0,
                'valid_chains': 0
            }
            
            for result in security_report['detailed_results']:
                score = security_enhancer._calculate_comprehensive_security_score(result)
                
                if score >= 80:
                    score_distribution[0] += 1
                elif score >= 60:
                    score_distribution[1] += 1
                elif score >= 40:
                    score_distribution[2] += 1
                else:
                    score_distribution[3] += 1
                
                if result['certificate_pinning']['verified']:
                    feature_stats['pinning'] += 1
                if result['https_enforcement']['enforced']:
                    feature_stats['https'] += 1
                if result['hsts']['enabled']:
                    feature_stats['hsts'] += 1
                if result.get('security_headers', {}).get('assessment', {}).get('has_csp', False):
                    feature_stats['good_headers'] += 1
                if result.get('certificate_chain_valid', False):
                    feature_stats['valid_chains'] += 1
            
            security_report['scoreDistribution'] = score_distribution
            security_report['featureStats'] = feature_stats
            
            logger.info(f"æ‰¹é‡å®‰å…¨åˆ†æå®Œæˆï¼Œå¹³å‡å®‰å…¨åˆ†æ•°: {security_report['summary']['security_score']:.1f}")
            
            return jsonify({
                'status': 'success',
                'security_report': security_report
            })
            
        except Exception as e:
            logger.error(f"æ‰¹é‡å®‰å…¨åˆ†æå¤±è´¥: {str(e)}")
            return jsonify({'status': 'error', 'error': f'æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}'}), 500
    
    @app.route('/api/security/analyze-pcap', methods=['POST'])
    def analyze_pcap_file():
        """åˆ†æPCAPæ–‡ä»¶å¹¶æå–åŸŸåè¿›è¡Œå®‰å…¨åˆ†æ"""
        pcap_path = None
        
        try:
            if 'file' not in request.files:
                return jsonify({'status': 'error', 'error': 'æœªä¸Šä¼ æ–‡ä»¶'}), 400
            
            file = request.files['file']
            if file.filename == '':
                return jsonify({'status': 'error', 'error': 'æœªé€‰æ‹©æ–‡ä»¶'}), 400
            
            timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
            filename = secure_filename(f"pcap_{timestamp}_{file.filename}")
            pcap_path = os.path.join(upload_folder, filename)
            file.save(pcap_path)
            
            logger.info(f"å¼€å§‹åˆ†æPCAPæ–‡ä»¶: {filename}")
            
            domains = extract_domains_from_pcap(pcap_path)
            
            if not domains:
                logger.warning("æ— æ³•ä»PCAPæ–‡ä»¶ä¸­æå–åŸŸå")
                empty_report = create_empty_security_report()
                if pcap_path and os.path.exists(pcap_path):
                    os.remove(pcap_path)
                return jsonify({
                    'status': 'success',
                    'security_report': empty_report,
                    'extracted_domains': [],
                    'note': 'æ— æ³•ä»PCAPæ–‡ä»¶ä¸­æå–åŸŸå'
                })
            
            logger.info(f"ä»PCAPæ–‡ä»¶ä¸­æå–åˆ° {len(domains)} ä¸ªåŸŸå")
            
            domain_stats = {
                'total_extracted': len(domains),
                'after_filtering': 0,
                'to_analyze': 0
            }
            
            filtered_domains = []
            for domain in domains:
                if is_valid_domain(domain):
                    filtered_domains.append(domain)
            
            domain_stats['after_filtering'] = len(filtered_domains)
            
            MAX_ANALYZE_DOMAINS = 20
            domains_to_analyze = filtered_domains[:MAX_ANALYZE_DOMAINS]
            domain_stats['to_analyze'] = len(domains_to_analyze)
            
            logger.info(f"PCAPåŸŸåç»Ÿè®¡: æå–{domain_stats['total_extracted']} -> è¿‡æ»¤å{domain_stats['after_filtering']} -> å®é™…åˆ†æ{domain_stats['to_analyze']}")
            
            from domain_saver import save_filtered_domains, save_domains_to_txt
            saved_files = {}
            if filtered_domains:
                json_path = save_filtered_domains(
                    filtered_domains, 
                    analysis_type="pcap", 
                    source_file=file.filename
                )
                txt_path = save_domains_to_txt(
                    filtered_domains,
                    analysis_type="pcap", 
                    source_file=file.filename
                )
                saved_files = {
                    'json': json_path,
                    'txt': txt_path
                }

            security_report = simple_security_analyze(domains_to_analyze)
            
            security_report['domain_stats'] = domain_stats
            
            if pcap_path and os.path.exists(pcap_path):
                os.remove(pcap_path)
            
            return jsonify({
                'status': 'success',
                'security_report': security_report,
                'extracted_domains': domains[:10],
                'domain_stats': domain_stats,
                'saved_files': saved_files
            })
            
        except Exception as e:
            logger.error(f"PCAPæ–‡ä»¶åˆ†æå¤±è´¥: {str(e)}")
            
            if pcap_path and os.path.exists(pcap_path):
                try:
                    os.remove(pcap_path)
                    logger.info("å·²æ¸…ç†ä¸´æ—¶PCAPæ–‡ä»¶")
                except Exception as cleanup_error:
                    logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(cleanup_error)}")
            
            empty_report = create_empty_security_report()
            return jsonify({
                'status': 'success',
                'security_report': empty_report,
                'extracted_domains': [],
                'note': f'PCAPåˆ†æå¤±è´¥: {str(e)}'
            })
    
    @app.route('/api/security/analyze-certificates', methods=['POST'])
    def analyze_certificate_files():
        """åˆ†æè¯ä¹¦æ–‡ä»¶æˆ–å‹ç¼©åŒ…å¹¶æå–åŸŸåè¿›è¡Œå®‰å…¨åˆ†æ"""
        try:
            analysis_type = request.form.get('analysis_type', 'der')
            file = request.files.get('file')
            
            if not file or file.filename == '':
                return jsonify({'status': 'error', 'error': 'æœªé€‰æ‹©æ–‡ä»¶'}), 400
            
            timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
            filename = secure_filename(f"cert_{timestamp}_{file.filename}")
            file_path = os.path.join(upload_folder, filename)
            file.save(file_path)
            
            logger.info(f"å¼€å§‹åˆ†æè¯ä¹¦æ–‡ä»¶: {filename}, ç±»å‹: {analysis_type}")
            
            domains = []
            certificate_analysis = []
            
            if analysis_type == 'zip':
                domains, cert_analysis_list = extract_domains_from_certificate_zip(file_path)
                certificate_analysis = cert_analysis_list
            else:
                domains, cert_info = extract_domains_from_der_file(file_path)
                certificate_analysis = [cert_info]
            
            if not domains:
                logger.warning(f"ä»è¯ä¹¦æ–‡ä»¶ä¸­æå–åˆ° 0 ä¸ªåŸŸå")
                
                feedback_message = build_certificate_feedback(certificate_analysis)
                
                cert_info = certificate_analysis[0] if certificate_analysis else {}
                logger.info(f"è¯ä¹¦ç±»å‹: {cert_info.get('type', 'æœªçŸ¥')}")
                logger.info(f"æ˜¯å¦æ˜¯CA: {cert_info.get('is_ca', False)}")
                logger.info(f"æ˜¯å¦è‡ªç­¾å: {cert_info.get('is_self_signed', False)}")
                logger.info(f"åé¦ˆä¿¡æ¯: {feedback_message}")
                
                if os.path.exists(file_path):
                    os.remove(file_path)
                
                return jsonify({
                    'status': 'info', 
                    'message': feedback_message,
                    'certificate_analysis': certificate_analysis,
                    'certificate_type': cert_info.get('type', 'æœªçŸ¥ç±»å‹'),
                    'is_ca': cert_info.get('is_ca', False),
                    'is_self_signed': cert_info.get('is_self_signed', False),
                    'subject': cert_info.get('subject', ''),
                    'issuer': cert_info.get('issuer', ''),
                    'extracted_domains_count': 0,
                    'certificate_details': cert_info
                })
            
            logger.info(f"ä»è¯ä¹¦æ–‡ä»¶ä¸­æå–åˆ° {len(domains)} ä¸ªåŸŸå")
                    
            domain_stats = {
                'total_extracted': len(domains),
                'after_filtering': 0,
                'to_analyze': 0
            }
            
            filtered_domains = []
            for domain in domains:
                if is_valid_domain(domain):
                    filtered_domains.append(domain)
            
            domain_stats['after_filtering'] = len(filtered_domains)
            
            MAX_ANALYZE_DOMAINS = 20
            domains_to_analyze = filtered_domains[:MAX_ANALYZE_DOMAINS]
            domain_stats['to_analyze'] = len(domains_to_analyze)
            
            logger.info(f"åŸŸååˆ†æç»Ÿè®¡: æå–{domain_stats['total_extracted']} -> è¿‡æ»¤å{domain_stats['after_filtering']} -> å®é™…åˆ†æ{domain_stats['to_analyze']}")
            
            from domain_saver import save_filtered_domains, save_domains_to_txt
            saved_files = {}
            if filtered_domains:
                json_path = save_filtered_domains(
                    filtered_domains,
                    analysis_type=f"cert_{analysis_type}",
                    source_file=file.filename
                )
                txt_path = save_domains_to_txt(
                    filtered_domains,
                    analysis_type=f"cert_{analysis_type}",
                    source_file=file.filename
                )
                saved_files = {
                    'json': json_path,
                    'txt': txt_path
                }
            
            security_report = simple_security_analyze(domains_to_analyze)
            
            security_report['domain_stats'] = domain_stats
            security_report['certificate_analysis'] = certificate_analysis
            security_report['saved_files'] = saved_files
            
            if os.path.exists(file_path):
                os.remove(file_path)
            
            return jsonify({
                "status": "success",
                "security_report": security_report,
                "extracted_domains_count": len(domains),
                "analyzed_domains_count": security_report['summary']['analyzed_domains'],
                "domain_stats": domain_stats,
                "certificate_analysis": certificate_analysis,
                "saved_files": saved_files
            })

        except Exception as e:
            logger.error(f"è¯ä¹¦æ–‡ä»¶åˆ†æå¤±è´¥: {str(e)}")
            if 'file_path' in locals() and os.path.exists(file_path):
                os.remove(file_path)
            return jsonify({'status': 'error', 'error': f'è¯ä¹¦åˆ†æå¤±è´¥: {str(e)}'}), 500
    
    # åˆ›å»ºå…¨å±€ä»»åŠ¡é˜Ÿåˆ—ï¼ˆç®€å•ç‰ˆæœ¬ï¼‰
    report_tasks = {}
    task_results = {}
    task_lock = threading.Lock()

    @app.route('/api/security/generate-report', methods=['POST'])
    def generate_security_report_api():
        """ä¸ºå®‰å…¨åˆ†æç”ŸæˆAIæŠ¥å‘Šï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰"""
        try:
            data = request.get_json()
        
            # ç”Ÿæˆå”¯ä¸€ä»»åŠ¡ID
            task_id = str(uuid.uuid4())
        
            # è®°å½•ä»»åŠ¡å¼€å§‹
            with task_lock:
                report_tasks[task_id] = {
                    'status': 'processing',
                    'created_at': datetime.now().isoformat(),
                    'data': data  # ä¿å­˜ä»»åŠ¡æ•°æ®
                }
        
            # å¯åŠ¨åå°çº¿ç¨‹å¤„ç†ä»»åŠ¡
            thread = threading.Thread(
                target=process_report_task,
                args=(task_id, data),
                daemon=True
            )
            thread.start()
        
            logger.info(f"æŠ¥å‘Šç”Ÿæˆä»»åŠ¡å·²æäº¤ï¼Œä»»åŠ¡ID: {task_id}")
        
            return jsonify({
                'status': 'processing',
                'task_id': task_id,
                'message': 'æŠ¥å‘Šç”Ÿæˆä»»åŠ¡å·²æäº¤ï¼Œè¯·ç¨åæŸ¥è¯¢ç»“æœ',
                'created_at': datetime.now().isoformat()
            })
        
        except Exception as e:
            logger.error(f"æŠ¥å‘Šä»»åŠ¡æäº¤å¤±è´¥: {str(e)}")
            return jsonify({'status': 'error', 'error': f'æŠ¥å‘Šä»»åŠ¡æäº¤å¤±è´¥: {str(e)}'}), 500

    def process_report_task(task_id, data):
        """åå°å¤„ç†æŠ¥å‘Šä»»åŠ¡"""
        try:
            logger.info(f"å¼€å§‹å¤„ç†æŠ¥å‘Šä»»åŠ¡: {task_id}")
        
            # è°ƒç”¨ä½ çš„æŠ¥å‘Šç”Ÿæˆå‡½æ•°
            from services.deepseek_service import generate_ai_report
        
            report_content = generate_ai_report(
                data, 
                source_type="security",
                original_filename=data.get('original_file', ''),
                report_type="security"
            )
             # ä¿®å¤1ï¼šæ¸…ç†æŠ¥å‘Šå†…å®¹ï¼Œç§»é™¤å¯èƒ½å¯¼è‡´JSONé—®é¢˜çš„å­—ç¬¦
            if report_content:
                # ç§»é™¤å¯èƒ½å¼•èµ·JSONè§£æé—®é¢˜çš„å­—ç¬¦
                report_content = report_content.replace('\n', '\\n').replace('\r', '\\r')
                # ç¡®ä¿æ²¡æœ‰æœªé—­åˆçš„å¼•å·
                report_content = report_content.replace('"', '\\"')
                # é™åˆ¶æŠ¥å‘Šé•¿åº¦ï¼Œé¿å…è¿‡é•¿
                if len(report_content) > 100000:  # é™åˆ¶ä¸º100Kå­—ç¬¦
                    report_content = report_content[:100000] + "\n\n[æŠ¥å‘Šå› è¿‡é•¿è¢«æˆªæ–­]"
        
            # ä¿®å¤2ï¼šç¡®ä¿æ•°æ®ç»“æ„æ­£ç¡®
            result_data = {
                'status': 'success',
                'report_content': report_content or 'æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†…å®¹ä¸ºç©º',
                'completed_at': datetime.now().isoformat(),
                'report_length': len(report_content) if report_content else 0
            }
        
            # ä¿®å¤3ï¼šè®°å½•æŠ¥å‘Šä¿¡æ¯ç”¨äºè°ƒè¯•
            logger.info(f"æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(report_content) if report_content else 0} å­—ç¬¦")
        
            with task_lock:
                task_results[task_id] = result_data
            
                    # ä»ä»»åŠ¡é˜Ÿåˆ—ç§»é™¤ï¼ˆå¯é€‰ï¼‰
            if task_id in report_tasks:
                    del report_tasks[task_id]
        
            logger.info(f"æŠ¥å‘Šä»»åŠ¡å®Œæˆ: {task_id}")
        
        except Exception as e:
            logger.error(f"æŠ¥å‘Šä»»åŠ¡å¤„ç†å¤±è´¥ {task_id}: {str(e)}")
        
            with task_lock:
                task_results[task_id] = {
                    'status': 'failed',
                    'error': str(e),
                    'completed_at': datetime.now().isoformat()
                }
            
                if task_id in report_tasks:
                    del report_tasks[task_id]
    
    @app.route('/api/security/report-status/<task_id>', methods=['GET'])
    def get_report_status(task_id):
        """è·å–æŠ¥å‘Šç”ŸæˆçŠ¶æ€"""
        try:
            with task_lock:
                logger.info(f"æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€: {task_id}")
            
                # å…ˆæ£€æŸ¥ç»“æœ
                if task_id in task_results:
                    result = task_results[task_id]
                    logger.info(f"ä»»åŠ¡ {task_id} ç»“æœ: {result}")
                    return jsonify(result)
            
                # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦ä»åœ¨å¤„ç†ä¸­
                elif task_id in report_tasks:
                    task_info = report_tasks[task_id]
                    logger.info(f"ä»»åŠ¡ {task_id} å¤„ç†ä¸­")
                    return jsonify({
                        'status': 'processing',
                        'created_at': task_info['created_at'],
                        'message': 'æŠ¥å‘Šç”Ÿæˆä¸­...'
                    })
            
                else:
                    logger.warning(f"ä»»åŠ¡ {task_id} ä¸å­˜åœ¨")
                    return jsonify({'status': 'not_found'})
                
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥ {task_id}: {str(e)}")
            return jsonify({'status': 'error', 'error': str(e)}), 500

        # å¯é€‰ï¼šæ¸…ç†è¿‡æœŸä»»åŠ¡çš„è·¯ç”±
    @app.route('/api/security/cleanup-tasks', methods=['POST'])
    def cleanup_tasks():
        """æ¸…ç†è¿‡æœŸä»»åŠ¡"""
        try:
            cleanup_count = 0
            current_time = datetime.now()
        
            with task_lock:
                # æ¸…ç†è¶…è¿‡1å°æ—¶çš„å·²å®Œæˆä»»åŠ¡
                task_ids_to_remove = []
                for task_id, result in task_results.items():
                    completed_time = datetime.fromisoformat(result['completed_at'])
                    if (current_time - completed_time).seconds > 3600:
                        task_ids_to_remove.append(task_id)
            
                for task_id in task_ids_to_remove:
                    del task_results[task_id]
                    cleanup_count += 1
            
                # æ¸…ç†è¶…è¿‡10åˆ†é’Ÿçš„æœªå®Œæˆä»»åŠ¡
                task_ids_to_remove = []
                for task_id, task_info in report_tasks.items():
                    created_time = datetime.fromisoformat(task_info['created_at'])
                    if (current_time - created_time).seconds > 600:
                        task_ids_to_remove.append(task_id)
            
                for task_id in task_ids_to_remove:
                    del report_tasks[task_id]
                    cleanup_count += 1
        
            logger.info(f"æ¸…ç†äº† {cleanup_count} ä¸ªè¿‡æœŸä»»åŠ¡")
            return jsonify({'status': 'success', 'cleaned_count': cleanup_count})
        
        except Exception as e:
            logger.error(f"æ¸…ç†ä»»åŠ¡å¤±è´¥: {str(e)}")
            return jsonify({'status': 'error', 'error': str(e)}), 500
    
    # ==================== å®‰å…¨åˆ†æè¾…åŠ©å‡½æ•° ====================
    
    def extract_domains_from_pcap(pcap_path):
        """ä»PCAPæ–‡ä»¶ä¸­æå–åŸŸå"""
        domains = set()
        
        try:
            from scapy.all import rdpcap, DNSQR, DNSRR, TLSClientHello
            packets = rdpcap(pcap_path)
            
            for packet in packets:
                if packet.haslayer(DNSQR):
                    dns_qry = packet[DNSQR]
                    domain = dns_qry.qname.decode('utf-8').rstrip('.')
                    if domain and '.' in domain:
                        domains.add(domain)
                
                if packet.haslayer(TLSClientHello):
                    try:
                        sni = packet[TLSClientHello].sni
                        if sni and '.' in sni:
                            domains.add(sni.decode('utf-8'))
                    except:
                        pass
                
                if packet.haslayer('Raw'):
                    try:
                        raw_data = packet['Raw'].load.decode('utf-8', errors='ignore')
                        if 'Host: ' in raw_data:
                            for line in raw_data.split('\n'):
                                if line.startswith('Host: '):
                                    host = line[6:].strip()
                                    if host and '.' in host:
                                        domains.add(host)
                                    break
                    except:
                        pass
                        
        except ImportError:
            logger.warning("Scapyæœªå®‰è£…ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•æå–åŸŸå")
            domains = extract_domains_with_tshark(pcap_path)
        except Exception as e:
            logger.error(f"PCAPåŸŸåæå–å¤±è´¥: {str(e)}")
        
        return list(domains)
    
    def extract_domains_with_tshark(pcap_path):
        """ä½¿ç”¨tsharkä»PCAPæ–‡ä»¶ä¸­æå–åŸŸåï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        domains = set()
        try:
            import subprocess
            
            env = os.environ.copy()
            env['PYTHONIOENCODING'] = 'utf-8'
            
            cmd_dns = ['tshark', '-r', pcap_path, '-Y', 'dns.qry.name', '-T', 'fields', '-e', 'dns.qry.name']
            
            logger.info(f"æ‰§è¡Œtsharkå‘½ä»¤æå–DNSåŸŸå: {' '.join(cmd_dns)}")
            
            result_dns = subprocess.run(
                cmd_dns, 
                capture_output=True, 
                text=True, 
                timeout=15,
                encoding='utf-8',
                errors='ignore',
                env=env
            )
            
            if result_dns.returncode == 0 and result_dns.stdout:
                for domain in result_dns.stdout.split('\n'):
                    domain = domain.strip()
                    if domain and '.' in domain and len(domain) < 253:
                        domain = domain.rstrip('.')
                        domains.add(domain)
                        logger.debug(f"ä»DNSæå–åˆ°åŸŸå: {domain}")
            
            cmd_tls = ['tshark', '-r', pcap_path, '-Y', 'tls.handshake.extensions_server_name', '-T', 'fields', '-e', 'tls.handshake.extensions_server_name']
            
            logger.info(f"æ‰§è¡Œtsharkå‘½ä»¤æå–TLS SNI: {' '.join(cmd_tls)}")
            
            result_tls = subprocess.run(
                cmd_tls, 
                capture_output=True, 
                text=True, 
                timeout=15,
                encoding='utf-8',
                errors='ignore',
                env=env
            )
            
            if result_tls.returncode == 0 and result_tls.stdout:
                for domain in result_tls.stdout.split('\n'):
                    domain = domain.strip()
                    if domain and '.' in domain and len(domain) < 253:
                        domains.add(domain)
                        logger.debug(f"ä»TLS SNIæå–åˆ°åŸŸå: {domain}")
            
            logger.info(f"tsharkå…±æå–åˆ° {len(domains)} ä¸ªå”¯ä¸€åŸŸå")
                        
        except subprocess.TimeoutExpired:
            logger.warning("tsharkå‘½ä»¤æ‰§è¡Œè¶…æ—¶ï¼Œè¿”å›å·²æå–çš„åŸŸå")
        except Exception as e:
            logger.error(f"tsharkåŸŸåæå–å¤±è´¥: {str(e)}")
        
        return list(domains)
    
    def build_certificate_feedback(certificate_analysis):
        """æ„å»ºè¯ä¹¦åˆ†æåé¦ˆä¿¡æ¯"""
        if not certificate_analysis:
            return "æ— æ³•åˆ†æè¯ä¹¦æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®"
        
        cert_info = certificate_analysis[0]
        
        if cert_info.get('error'):
            return f"è¯ä¹¦è§£æé”™è¯¯: {cert_info['error']}"
        
        feedback_parts = []
        
        cert_type = cert_info.get('type', 'æœªçŸ¥ç±»å‹')
        feedback_parts.append(f"ğŸ“„ è¯ä¹¦ç±»å‹: {cert_type}")
        
        subject = cert_info.get('subject', '')
        if subject:
            feedback_parts.append(f"ğŸ·ï¸ è¯ä¹¦ä¸»é¢˜: {subject}")
        
        issuer = cert_info.get('issuer', '')
        if issuer:
            feedback_parts.append(f"ğŸ¢ é¢å‘æœºæ„: {issuer}")
        
        if cert_info.get('not_valid_before') and cert_info.get('not_valid_after'):
            feedback_parts.append(f"ğŸ“… æœ‰æ•ˆæœŸ: {cert_info['not_valid_before'][:10]} è‡³ {cert_info['not_valid_after'][:10]}")
        
        if cert_info.get('is_ca'):
            if cert_info.get('is_self_signed'):
                feedback_parts.append("ğŸ” è¿™æ˜¯ä¸€ä¸ªè‡ªç­¾åæ ¹è¯ä¹¦")
                feedback_parts.append("ğŸ’¡ ç”¨é€”: ç”¨äºå»ºç«‹ä¿¡ä»»é“¾ï¼Œç­¾å‘å…¶ä»–è¯ä¹¦")
                feedback_parts.append("â“ åŸå› : æ ¹è¯ä¹¦ä¸åŒ…å«å¯è®¿é—®çš„åŸŸå")
            else:
                feedback_parts.append("ğŸ” è¿™æ˜¯ä¸€ä¸ªä¸­é—´CAè¯ä¹¦")
                feedback_parts.append("ğŸ’¡ ç”¨é€”: ç”¨äºç­¾å‘ç»ˆç«¯å®ä½“è¯ä¹¦")
                feedback_parts.append("â“ åŸå› : CAè¯ä¹¦ä¸åŒ…å«å¯è®¿é—®çš„åŸŸå")
            
            feedback_parts.append("âœ… å»ºè®®: è¯·ä¸Šä¼ å¶å­è¯ä¹¦ï¼ˆç»ˆç«¯å®ä½“è¯ä¹¦ï¼‰è¿›è¡Œåˆ†æ")
            
        elif cert_info.get('type', '').startswith('å¶å­è¯ä¹¦'):
            if not cert_info.get('has_domains'):
                feedback_parts.append("â“ åŸå› : è¯ä¹¦ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„åŸŸåä¿¡æ¯")
                feedback_parts.append("ğŸ’¡ å¯èƒ½åŸå› :")
                feedback_parts.append("   â€¢ è¯ä¹¦ç”¨äºä»£ç ç­¾åæˆ–æ–‡æ¡£ç­¾å")
                feedback_parts.append("   â€¢ è¯ä¹¦ç”¨äºè®¾å¤‡è®¤è¯è€Œéç½‘ç«™")
                feedback_parts.append("   â€¢ è¯ä¹¦çš„Common Nameä¸æ˜¯åŸŸåæ ¼å¼")
                feedback_parts.append("âœ… å»ºè®®: è¯·ä¸Šä¼ ç”¨äºç½‘ç«™çš„è¯ä¹¦")
            else:
                feedback_parts.append("âœ… è¿™æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ç½‘ç«™è¯ä¹¦")
        
        elif cert_info.get('is_self_signed'):
            feedback_parts.append("ğŸ” è¿™æ˜¯ä¸€ä¸ªè‡ªç­¾åè¯ä¹¦")
            feedback_parts.append("ğŸ’¡ ç”¨é€”: é€šå¸¸ç”¨äºå†…éƒ¨æµ‹è¯•æˆ–å¼€å‘ç¯å¢ƒ")
            feedback_parts.append("â“ åŸå› : è‡ªç­¾åè¯ä¹¦å¯èƒ½ä¸åŒ…å«æ ‡å‡†åŸŸå")
            feedback_parts.append("âœ… å»ºè®®: å¯¹äºç”Ÿäº§ç¯å¢ƒï¼Œè¯·ä½¿ç”¨CAç­¾å‘çš„è¯ä¹¦")
        
        return "\n".join(feedback_parts)
    
    def extract_domains_from_certificate_zip(zip_path):
        """ä»è¯ä¹¦å‹ç¼©åŒ…ä¸­æå–åŸŸå"""
        domains = set()
        certificate_analysis_list = []
        extract_dir = os.path.join(upload_folder, f"extract_{datetime.now().strftime('%Y%m%d%H%M%S')}")
        
        try:
            os.makedirs(extract_dir, exist_ok=True)
            extract_archive(zip_path, extract_dir)
            
            cert_files = find_certificate_files(extract_dir)
            
            for cert_file in cert_files:
                try:
                    file_domains, cert_info = extract_domains_from_der_file(cert_file)
                    domains.update(file_domains)
                    cert_info['filename'] = os.path.basename(cert_file)
                    certificate_analysis_list.append(cert_info)
                except Exception as e:
                    logger.warning(f"æ— æ³•ä»æ–‡ä»¶ {cert_file} æå–åŸŸå: {str(e)}")
                    certificate_analysis_list.append({
                        'filename': os.path.basename(cert_file),
                        'error': str(e)
                    })
                    continue
                    
        except Exception as e:
            logger.error(f"è¯ä¹¦å‹ç¼©åŒ…å¤„ç†å¤±è´¥: {str(e)}")
        finally:
            if os.path.exists(extract_dir):
                shutil.rmtree(extract_dir, ignore_errors=True)
        
        return list(domains), certificate_analysis_list
    
    def extract_domains_from_der_file(der_path):
        """ä»å•ä¸ªè¯ä¹¦æ–‡ä»¶ä¸­æå–åŸŸåï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰"""
        domains = set()
        certificate_info = {
            'type': 'unknown',
            'subject': '',
            'issuer': '',
            'is_ca': False,
            'has_domains': False,
            'is_self_signed': False,
            'certificate_details': {}
        }
        
        try:
            logger.info(f"å¼€å§‹è§£æè¯ä¹¦æ–‡ä»¶: {der_path}")
            
            with open(der_path, 'rb') as f:
                cert_data = f.read()
            
            logger.info(f"æ–‡ä»¶å¤§å°: {len(cert_data)} å­—èŠ‚")
            
            from cryptography import x509
            from cryptography.hazmat.backends import default_backend
            
            cert = None
            parse_attempts = []
            
            try:
                cert = x509.load_der_x509_certificate(cert_data, default_backend())
                parse_attempts.append("DERè§£ææˆåŠŸ")
            except Exception as e1:
                parse_attempts.append(f"DERè§£æå¤±è´¥: {str(e1)}")
                try:
                    cert = x509.load_pem_x509_certificate(cert_data, default_backend())
                    parse_attempts.append("PEMè§£ææˆåŠŸ")
                except Exception as e2:
                    parse_attempts.append(f"PEMè§£æå¤±è´¥: {str(e2)}")
            
            if not cert:
                logger.error(f"æ‰€æœ‰è§£æå°è¯•éƒ½å¤±è´¥: {'; '.join(parse_attempts)}")
                certificate_info['error'] = 'è¯ä¹¦æ ¼å¼ä¸æ”¯æŒ'
                certificate_info['parse_attempts'] = parse_attempts
                return [], certificate_info
            
            logger.info(f"è¯ä¹¦è§£ææˆåŠŸï¼Œå¼€å§‹æå–åŸŸå")
            
            certificate_info['subject'] = cert.subject.rfc4514_string()
            certificate_info['issuer'] = cert.issuer.rfc4514_string()
            
            certificate_info['is_self_signed'] = (cert.subject == cert.issuer)
            
            try:
                basic_constraints = cert.extensions.get_extension_for_oid(x509.ExtensionOID.BASIC_CONSTRAINTS)
                certificate_info['is_ca'] = basic_constraints.value.ca
                if basic_constraints.value.ca:
                    if certificate_info['is_self_signed']:
                        certificate_info['type'] = 'è‡ªç­¾åæ ¹è¯ä¹¦'
                    else:
                        certificate_info['type'] = 'ä¸­é—´CAè¯ä¹¦'
                else:
                    certificate_info['type'] = 'å¶å­è¯ä¹¦'
            except x509.ExtensionNotFound:
                certificate_info['is_ca'] = False
                certificate_info['type'] = 'å¶å­è¯ä¹¦ï¼ˆå¯èƒ½ï¼‰'
            
            certificate_info['not_valid_before'] = cert.not_valid_before.isoformat()
            certificate_info['not_valid_after'] = cert.not_valid_after.isoformat()
            
            certificate_info['serial_number'] = str(cert.serial_number)
            
            subject = cert.subject
            cn_attributes = subject.get_attributes_for_oid(x509.NameOID.COMMON_NAME)
            if cn_attributes:
                for attr in cn_attributes:
                    domain = attr.value
                    if (domain and '.' in domain and 
                        not domain.startswith('*') and
                        len(domain) > 3 and len(domain) < 253 and
                        is_valid_domain(domain)):
                        domains.add(domain)
                        certificate_info['has_domains'] = True
                        logger.info(f"ä»CNæå–åˆ°åŸŸå: {domain}")
                    else:
                        logger.info(f"CNå€¼ '{domain}' ä¸æ˜¯æœ‰æ•ˆåŸŸåæ ¼å¼")
            
            try:
                san_ext = cert.extensions.get_extension_for_oid(x509.ExtensionOID.SUBJECT_ALTERNATIVE_NAME)
                san_domains = san_ext.value.get_values_for_type(x509.DNSName)
                for domain in san_domains:
                    if (domain and '.' in domain and 
                        len(domain) > 3 and len(domain) < 253 and
                        is_valid_domain(domain)):
                        domains.add(domain)
                        certificate_info['has_domains'] = True
                logger.info(f"ä»SANæå–åˆ°åŸŸå: {san_domains}")
            except x509.ExtensionNotFound:
                logger.info("æœªæ‰¾åˆ°SANæ‰©å±•")
            except Exception as e:
                logger.warning(f"SANæ‰©å±•è§£æå¤±è´¥: {str(e)}")
            
            if not domains:
                logger.info("å°è¯•ä»å…¶ä»–åç§°å±æ€§ä¸­æå–åŸŸå")
                for attr in subject:
                    try:
                        value = attr.value
                        if (isinstance(value, str) and '.' in value and 
                            not value.startswith('*') and
                            len(value) > 3 and len(value) < 253 and
                            is_valid_domain(value)):
                            domains.add(value)
                            certificate_info['has_domains'] = True
                            logger.info(f"ä»å±æ€§ {attr.oid._name} æå–åˆ°åŸŸå: {value}")
                    except Exception as e:
                        continue
            
            logger.info(f"æ€»å…±æå–åˆ° {len(domains)} ä¸ªåŸŸå: {list(domains)}")
            logger.info(f"è¯ä¹¦ä¿¡æ¯: {certificate_info}")
                
        except Exception as e:
            logger.error(f"è¯ä¹¦è§£æå¤±è´¥ {der_path}: {str(e)}\n{traceback.format_exc()}")
            certificate_info['error'] = f"è¯ä¹¦è§£æå¤±è´¥: {str(e)}"
        
        return list(domains), certificate_info
    
    def simple_security_analyze(domains):
        """ç®€åŒ–çš„å®‰å…¨åˆ†æå‡½æ•°"""
        results = {
            'summary': {
                'security_score': 0,
                'domains_with_https_enforcement': 0,
                'domains_with_hsts': 0,
                'domains_with_valid_certificate_chains': 0,
                'total_domains': len(domains),
                'analyzed_domains': 0
            },
            'detailed_results': [],
            'scoreDistribution': [0, 0, 0, 0],
            'featureStats': {
                'https': 0,
                'hsts': 0,
                'good_headers': 0,
                'valid_chains': 0
            }
        }
        
        analyzed_count = 0
        total_score = 0
        
        logger.info(f"å¼€å§‹åˆ†æ {len(domains)} ä¸ªåŸŸå")
        
        for i, domain in enumerate(domains, 1):
            try:
                logger.info(f"åˆ†æè¿›åº¦: {i}/{len(domains)} - {domain}")
                
                domain_result = analyze_single_domain_simple(domain)
                if domain_result and domain_result.get('security_score', 0) > 0:
                    results['detailed_results'].append(domain_result)
                    score = domain_result.get('security_score', 0)
                    total_score += score
                    analyzed_count += 1
                    
                    if domain_result.get('https_enforcement', {}).get('enforced'):
                        results['featureStats']['https'] += 1
                        results['summary']['domains_with_https_enforcement'] += 1
                        
                    if domain_result.get('hsts', {}).get('enabled'):
                        results['featureStats']['hsts'] += 1
                        results['summary']['domains_with_hsts'] += 1
                        
                    if domain_result.get('certificate_chain_valid'):
                        results['featureStats']['valid_chains'] += 1
                        results['summary']['domains_with_valid_certificate_chains'] += 1
                    
                    headers = domain_result.get('security_headers', {}).get('assessment', {})
                    if headers.get('has_csp') or headers.get('has_x_frame_options'):
                        results['featureStats']['good_headers'] += 1
                    
                    if score >= 80:
                        results['scoreDistribution'][0] += 1
                    elif score >= 60:
                        results['scoreDistribution'][1] += 1
                    elif score >= 40:
                        results['scoreDistribution'][2] += 1
                    else:
                        results['scoreDistribution'][3] += 1
                        
            except Exception as e:
                logger.warning(f"åŸŸå {domain} åˆ†æå¤±è´¥: {str(e)}")
                continue
        
        if analyzed_count > 0:
            results['summary']['security_score'] = round(total_score / analyzed_count, 1)
            results['summary']['analyzed_domains'] = analyzed_count
        
        logger.info(f"å®‰å…¨åˆ†æå®Œæˆ: æˆåŠŸåˆ†æ {analyzed_count}/{len(domains)} ä¸ªåŸŸå")
        
        return results
    
    def analyze_single_domain_simple(domain):
        """ç®€åŒ–ç‰ˆå•åŸŸååˆ†æ"""
        if not is_valid_domain(domain):
            return None
        
        result = {
            'domain': domain,
            'https_enforcement': {'enforced': False, 'status': 'æœªçŸ¥'},
            'hsts': {'enabled': False, 'status': 'æœªçŸ¥'},
            'security_headers': {
                'assessment': {
                    'has_csp': False,
                    'has_x_content_type_options': False,
                    'has_x_frame_options': False,
                    'has_referrer_policy': False
                }
            },
            'certificate_chain_valid': False,
            'security_score': 0
        }
        
        try:
            import requests
            
            https_result = check_https_simple(domain)
            result['https_enforcement'] = https_result
            
            hsts_result = check_hsts_simple(domain)
            result['hsts'] = hsts_result
            
            headers_result = check_security_headers_simple(domain)
            if headers_result:
                result['security_headers']['assessment'] = headers_result
            
            result['certificate_chain_valid'] = True
            
            score = 0
            if https_result.get('enforced'):
                score += 30
            if hsts_result.get('enabled'):
                score += 30
            if headers_result.get('has_csp'):
                score += 10
            if headers_result.get('has_x_content_type_options'):
                score += 5
            if headers_result.get('has_x_frame_options'):
                score += 5
            if headers_result.get('has_referrer_policy'):
                score += 5
            if result['certificate_chain_valid']:
                score += 15
                
            result['security_score'] = min(score, 100)
            
        except Exception as e:
            logger.warning(f"åŸŸå {domain} ç®€åŒ–åˆ†æå¼‚å¸¸: {str(e)}")
            result['security_score'] = 0
        
        return result
    
    def check_https_simple(domain):
        """ç®€åŒ–HTTPSæ£€æŸ¥"""
        import requests
        
        try:
            timeout = 3

            http_url = f"http://{domain}"
            response = requests.get(http_url, timeout=5, allow_redirects=False)
            if response.status_code in [301, 302, 307, 308]:
                location = response.headers.get('location', '')
                if location.startswith('https://'):
                    return {'enforced': True, 'status': 'å·²å¯ç”¨é‡å®šå‘'}
            
            https_url = f"https://{domain}"
            response = requests.get(https_url, timeout=5)
            if response.status_code == 200:
                return {'enforced': True, 'status': 'HTTPSå¯ç›´æ¥è®¿é—®'}
                
        except requests.exceptions.SSLError:
            return {'enforced': False, 'status': 'SSLè¯ä¹¦é”™è¯¯'}
        except requests.exceptions.ConnectTimeout:
            return {'enforced': False, 'status': 'è¿æ¥è¶…æ—¶'}
        except requests.exceptions.ConnectionError:
            return {'enforced': False, 'status': 'è¿æ¥å¤±è´¥'}
        except Exception:
            pass
        
        return {'enforced': False, 'status': 'æœªå¯ç”¨'}
    
    def check_hsts_simple(domain):
        """ç®€åŒ–HSTSæ£€æŸ¥"""
        import requests
        try:
            https_url = f"https://{domain}"
            response = requests.get(https_url, timeout=5)
            hsts_header = response.headers.get('strict-transport-security', '')
            
            if hsts_header:
                return {'enabled': True, 'status': 'å·²é…ç½®'}
            else:
                return {'enabled': False, 'status': 'æœªé…ç½®'}
                
        except Exception:
            return {'enabled': False, 'status': 'æ£€æŸ¥å¤±è´¥'}
    
    def check_security_headers_simple(domain):
        """ç®€åŒ–å®‰å…¨å¤´æ£€æŸ¥"""
        import requests
        try:
            https_url = f"https://{domain}"
            response = requests.get(https_url, timeout=5)
            headers = response.headers
            
            return {
                'has_csp': 'content-security-policy' in headers,
                'has_x_content_type_options': 'x-content-type-options' in headers,
                'has_x_frame_options': 'x-frame-options' in headers,
                'has_referrer_policy': 'referrer-policy' in headers
            }
        except Exception:
            return {
                'has_csp': False,
                'has_x_content_type_options': False,
                'has_x_frame_options': False,
                'has_referrer_policy': False
            }
    
    def create_empty_security_report():
        """åˆ›å»ºç©ºçš„å®‰å…¨æŠ¥å‘Š"""
        return {
            'summary': {
                'security_score': 0,
                'domains_with_https_enforcement': 0,
                'domains_with_hsts': 0,
                'domains_with_valid_certificate_chains': 0,
                'total_domains': 0,
                'analyzed_domains': 0
            },
            'detailed_results': [],
            'scoreDistribution': [0, 0, 0, 0],
            'featureStats': {
                'https': 0,
                'hsts': 0,
                'good_headers': 0,
                'valid_chains': 0
            },
            'domain_stats': {
                'total_extracted': 0,
                'after_filtering': 0,
                'to_analyze': 0,
                'successfully_analyzed': 0
            },
            'saved_files': { 
                'json': None,
                'txt': None
            },
            'recommendations': [
                "PCAPæ–‡ä»¶åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®",
                "ç¡®ä¿PCAPæ–‡ä»¶åŒ…å«TLS/SSLæ¡æ‰‹æµé‡",
                "å°è¯•é‡æ–°ä¸Šä¼ æ–‡ä»¶æˆ–ä½¿ç”¨å…¶ä»–PCAPæ–‡ä»¶"
            ]
        }
    
    def save_report_to_file(report_content, source_type, original_filename, reports_folder):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        safe_filename = secure_filename(original_filename or 'unknown') if original_filename else 'unknown'
        report_filename = f"cert_report_{source_type}_{safe_filename}_{timestamp}.txt"
        report_path = os.path.join(reports_folder, report_filename)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        return report_path, report_filename